{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deadfish-hk/AcuCount_imageset/blob/main/MMrotate_training_github_v0_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMvMkyrDj7CG"
      },
      "outputs": [],
      "source": [
        "# This ipynb script is adapted from the MMrotate colab tutorial in (https://github.com/open-mmlab/mmrotate/blob/main/demo/MMRotate_Tutorial.ipynb).\n",
        "# Some modifications were made for the script to run seamlessly with the needle training set and configurations.\n",
        "# After the training, you shall obtain the .pth files under the directory which allows you to undergo further inference and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_7Rf69ti6e2"
      },
      "outputs": [],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezQr0lcdiAdb"
      },
      "outputs": [],
      "source": [
        "# Clone the AcuCount Repo for dataset and configs\n",
        "!git clone https://github.com/Deadfish-hk/AcuCount_imageset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjDgzCVxycAC"
      },
      "outputs": [],
      "source": [
        "# Download the AcuCount model stored in Google drive for demostration\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=11qKHCZYwAelya_bHDej4xDTKu7k9eb8z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjPj75c9cuXP"
      },
      "outputs": [],
      "source": [
        "# Download the AcuCount training imageset stored in Google drive for model training\n",
        "!gdown https://drive.google.com/uc?id=1_7vEBMvhG_Eu6CcPIFVV3PnjLkLGAFtr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bej4KheNjVmu"
      },
      "outputs": [],
      "source": [
        "# Install dependencies: (use cu116 because colab has CUDA 11.6)\n",
        "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install mmcv-full and mmdetection thus we could use CUDA operators\n",
        "!pip3 install -U openmim\n",
        "!mim install mmdet\\<3.0.0\n",
        "!mim install mmcv-full==1.6.2\n",
        "\n",
        "# Install mmrotate\n",
        "!git clone --branch v0.3.4 https://github.com/open-mmlab/mmrotate.git\n",
        "%cd mmrotate\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFTv0E2QjrcB"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGJYdH68jsUA"
      },
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMRotate installation\n",
        "import mmrotate\n",
        "print(mmrotate.__version__)\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ss1wbKLhDUB"
      },
      "outputs": [],
      "source": [
        "# Download the pre-trained Oriented R-CNN weights\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmrotate/v0.1.0/oriented_rcnn/oriented_rcnn_r50_fpn_1x_dota_le90/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth \\\n",
        "      -O checkpoints/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OplKfHQehlTC"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "from mmrotate.models import build_detector\n",
        "\n",
        "# Choose to use a config and initialize the detector\n",
        "config = '/content/AcuCount_imageset/AcuCount_detection_model_config.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = '/content/AcuCount_detection_model.pth'\n",
        "\n",
        "# Set the device to be used for evaluation\n",
        "device='cuda:0'\n",
        "\n",
        "# Load the config\n",
        "config = mmcv.Config.fromfile(config)\n",
        "# Set pretrained to be None since we do not need pretrained model here\n",
        "config.model.pretrained = None\n",
        "\n",
        "# Initialize the detector\n",
        "model = build_detector(config.model)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = load_checkpoint(model, checkpoint, map_location=device)\n",
        "\n",
        "# Set the classes of models for inference\n",
        "model.CLASSES = checkpoint['meta']['CLASSES']\n",
        "\n",
        "# We need to set the model's cfg for inference\n",
        "model.cfg = config\n",
        "\n",
        "# Convert the model to GPU\n",
        "model.to(device)\n",
        "# Convert the model into evaluation mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eSZvK8d8wqa6"
      },
      "outputs": [],
      "source": [
        "# Lets try visualize an example image\n",
        "\n",
        "img = mmcv.imread('/content/AcuCount_imageset/Validation_imageset/Copper_and_Silver_validation/Copper_and_Silver_0030.jpg')\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result, score_thr=0.5, palette='dota')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03ZffmINfMLL"
      },
      "outputs": [],
      "source": [
        "!unzip /content/AcuCount_training_dota.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5_TAVBFklfg"
      },
      "outputs": [],
      "source": [
        "# Check the directory structure of the data by installing tree\n",
        "# Note that the imageset contains 590 training images and 79 testing images, So a total of 1338 files including annotation txt files.\n",
        "\n",
        "!apt-get -q install tree\n",
        "!tree /content/mmrotate/final_needle_combined_dota"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w94TbWFlEhg"
      },
      "outputs": [],
      "source": [
        "# Check the label of a single image\n",
        "!cat final_needle_combined_dota/train/training_0429.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3G7XAGIlKob"
      },
      "outputs": [],
      "source": [
        "from mmrotate.datasets.builder import ROTATED_DATASETS\n",
        "from mmrotate.datasets.dota import DOTADataset\n",
        "\n",
        "\n",
        "@ROTATED_DATASETS.register_module()\n",
        "class TinyDataset(DOTADataset):\n",
        "    CLASSES = ('needle', )     # Input the name of your class label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1U2-hv1lQ7h"
      },
      "outputs": [],
      "source": [
        "# Import config file from AcuCount Repo\n",
        "\n",
        "from mmcv import Config\n",
        "cfg = Config.fromfile('/content/AcuCount_imageset/AcuCount_detection_model_config.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwWV88uDlVv2"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'TinyDataset'\n",
        "cfg.data_root = 'final_needle_combined_dota/'\n",
        "\n",
        "cfg.data.test.type = 'TinyDataset'\n",
        "cfg.data.test.data_root = 'final_needle_combined_dota/'\n",
        "cfg.data.test.ann_file = 'val'\n",
        "cfg.data.test.img_prefix = 'images'\n",
        "\n",
        "cfg.data.train.type = 'TinyDataset'\n",
        "cfg.data.train.data_root = 'final_needle_combined_dota/'\n",
        "cfg.data.train.ann_file = 'train'\n",
        "cfg.data.train.img_prefix = 'images'\n",
        "\n",
        "cfg.data.val.type = 'TinyDataset'\n",
        "cfg.data.val.data_root = 'final_needle_combined_dota/'\n",
        "cfg.data.val.ann_file = 'val'\n",
        "cfg.data.val.img_prefix = 'images'\n",
        "\n",
        "# modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head.num_classes = 1\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "cfg.optimizer.lr = 0.01\n",
        "cfg.lr_config.step = [53, 72]\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.runner.max_epochs = 80\n",
        "cfg.log_config.interval = 10\n",
        "\n",
        "cfg.model.rpn_head.anchor_generator.ratios = [0.0625, 0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0] #0.5, 1.0, 2.0 # [0.0625, 0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0, 16.0]\n",
        "\n",
        "cfg.model.test_cfg.rcnn.nms.iou_thr = 0.3 # 0.25 # 0.35 #optimal 0.3\n",
        "\n",
        "cfg.test_pipeline[1].img_scale = (960, 1280)\n",
        "\n",
        "cfg.data.val.pipeline[1].img_scale = (960, 1280)\n",
        "\n",
        "cfg.data.test.pipeline[1].img_scale = (960, 1280)\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 10\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 10\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(0, 1)\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "#print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS9iCKDvldZ8"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import mmcv\n",
        "\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "cfg.device = 'cuda'\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "cfg.device = 'cuda'\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E5dC1ouyC5D"
      },
      "outputs": [],
      "source": [
        "# Validate the dataset with display of model inference time\n",
        "\n",
        "import glob\n",
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "from mmrotate.models import build_detector\n",
        "import time\n",
        "\n",
        "import logging\n",
        "\n",
        "# Logging module\n",
        "\n",
        "logger = logging.getLogger()\n",
        "fhandler = logging.FileHandler(filename='/content/timeevent.log', mode='a')\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "fhandler.setFormatter(formatter)\n",
        "logger.addHandler(fhandler)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Counting function\n",
        "\n",
        "def counting(result):\n",
        "  count = 0\n",
        "  count_order = 0\n",
        "  count_list = result[0]\n",
        "  for item in np.nditer(count_list):\n",
        "    box_score = count_list[count_order][5]\n",
        "    if box_score > 0.5:\n",
        "      count = count + 1\n",
        "      count_order = count_order + 1\n",
        "      if count_order == len(count_list):\n",
        "        break\n",
        "    if box_score < 0.5:\n",
        "      count_order = count_order + 1\n",
        "      if count_order == len(count_list):\n",
        "        break\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYDrReSvg82g"
      },
      "outputs": [],
      "source": [
        "# Validate the dataset with model inference time\n",
        "# Change the directory path for detection of different needles (Copper, silver, copper_and_silver)\n",
        "\n",
        "png_order = 0\n",
        "png_list = glob.glob('/content/AcuCount_imageset/Validation_imageset/Copper_and_Silver_validation/*jpg')\n",
        "for item in png_list:\n",
        "  png_filename = png_list[png_order]\n",
        "  saved_filename = png_filename[-8:]\n",
        "  img = mmcv.imread(f'{png_filename}')\n",
        "  start_time = time.time()\n",
        "  result = inference_detector(model, img)\n",
        "  elapsed_time = time.time() - start_time\n",
        "  logger.info(f\"Inference done. elapsed time:{elapsed_time}\")\n",
        "  counting_result = counting(result)\n",
        "  show_result_pyplot(model, img, result, score_thr=0.5, out_file=f'/content/Final_testing/copper_and_silver/{counting_result}_{saved_filename}')\n",
        "  png_order = png_order + 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}